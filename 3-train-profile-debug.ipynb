{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.debugger import (\n",
    "    # profiler config\n",
    "    ProfilerConfig,\n",
    "    FrameworkProfile,\n",
    "    DetailedProfilingConfig,\n",
    "    DataloaderProfilingConfig,\n",
    "    PythonProfilingConfig,\n",
    "    PythonProfiler,\n",
    "    cProfileTimer,\n",
    "    # debugger config\n",
    "    DebuggerHookConfig,\n",
    "    CollectionConfig,\n",
    "    # rules\n",
    "    Rule,\n",
    "    ProfilerRule,\n",
    "    rule_configs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoleArn: arn:aws:iam::658994994074:role/service-role/AmazonSageMaker-ExecutionRole-20211220T111268\n",
      "Region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "print(\"RoleArn:\", role)\n",
    "\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "print(\"Region:\", region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Specify the profiler configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler_config = ProfilerConfig(\n",
    "    # Record system metrics every 500 milliseconds\n",
    "    system_monitor_interval_millis=500,\n",
    "    # Also collect data from Tensorflow's built-in Profiler\n",
    "    # such as data from the initialization stage, data loaders,\n",
    "    # detailed profiling between training steps etc.\n",
    "    framework_profile_params=FrameworkProfile(\n",
    "        # Collect data from Tensorflow's built-in profiler\n",
    "        detailed_profiling_config=DetailedProfilingConfig(\n",
    "            start_step=5, \n",
    "            num_steps=1\n",
    "        ),\n",
    "        # Profile data-loaders\n",
    "        dataloader_profiling_config=DataloaderProfilingConfig(\n",
    "            start_step=7, \n",
    "            num_steps=1\n",
    "        ),\n",
    "        # Activate the Python and cPython native profilers!\n",
    "        python_profiling_config=PythonProfilingConfig(\n",
    "            start_step=9, \n",
    "            num_steps=1, \n",
    "            python_profiler=PythonProfiler.CPROFILE, \n",
    "            cprofile_timer=cProfileTimer.TOTAL_TIME\n",
    "        )\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Specify the Debugger configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the debugger to save tensors collected during training time, such as losses, weights, gradients, biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and debugger configuration\n",
    "debugger_hook_config = DebuggerHookConfig(\n",
    "    # Specify what \"kind\" of tensors should be collected by the debugger\n",
    "    # For more information on collections, see:\n",
    "    # https://github.com/awslabs/sagemaker-debugger/blob/master/docs/api.md#collection\n",
    "    collection_configs=[\n",
    "        # Collections that debugger knows how to collect\n",
    "        # like weights, gradients, losses and biases\n",
    "        CollectionConfig(name=\"weights\"),\n",
    "        \n",
    "        # NOT NEEDED: Note that gradients and losses are collected anyway\n",
    "        # because  some rules require them (loss not decreasing, vanishing gradients)\n",
    "        #CollectionConfig(name=\"gradients\"),\n",
    "        #CollectionConfig(name=\"losses\"),\n",
    "        \n",
    "        CollectionConfig(name=\"biases\"),\n",
    "        # and a custom collection defined by a regex\n",
    "        CollectionConfig(\n",
    "            name=\"conv0_tensors\",\n",
    "            parameters={\n",
    "                # save all tensors whose name starts with 'conv0.'\n",
    "                \"include_regex\": \"conv0.*\",\n",
    "                # save these tensors every 100 steps (batches)\n",
    "                \"save_interval\": \"100\"\n",
    "            }\n",
    "        ),\n",
    "    ],\n",
    "    hook_parameters={\n",
    "        'save_interval': '10'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Specify monitoring rules\n",
    "\n",
    "We also want debugger to monitor tensors emitted during training and alert us if certain conditions are breached.\n",
    "In this example, we will enable the following rules:\n",
    "\n",
    "Debugger rules enabled:\n",
    "* loss is not decreasing\n",
    "* overfit\n",
    "* overtraining\n",
    "* stalled training\n",
    "* vanishing gradients\n",
    "* class imbalance\n",
    "\n",
    "Profiler rules enabled:\n",
    "* CPU bottlenecks\n",
    "* I/O Bottlenecks\n",
    "* GPU utilization\n",
    "* Multi-GPU LoadBalancing\n",
    "* GPU memory Analysis\n",
    "* etc.\n",
    "\n",
    "\n",
    "Debugger already provides a set of built-in rules, but we can also add our own custom rules.\n",
    "For a complete list of rules, see [Configure Debugger Built-in Rules](https://docs.aws.amazon.com/sagemaker/latest/dg/use-debugger-built-in-rules.html) and [Profiling report](https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-profiling-report.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = [\n",
    "    # add all monitoring and profiling rules\n",
    "    ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "    # loss not decreasing\n",
    "    Rule.sagemaker(rule_configs.loss_not_decreasing()),\n",
    "    Rule.sagemaker(rule_configs.overfit()),\n",
    "    Rule.sagemaker(rule_configs.overtraining()),\n",
    "    Rule.sagemaker(rule_configs.stalled_training_rule()),\n",
    "    Rule.sagemaker(rule_configs.vanishing_gradient()),\n",
    "    Rule.sagemaker(rule_configs.class_imbalance()),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare and launch a training job "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the instance type and count, the image, the training script and the debugger/profiler configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a training job\n",
    "estimator = TensorFlow(\n",
    "    # Provide our notebook execution role to grant access to the Training Job API\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    # Specify a docker image with Tensorflow 2.3.1\n",
    "    image_uri=f\"763104351884.dkr.ecr.{region}.amazonaws.com/tensorflow-training:2.3.1-gpu-py37-cu110-ubuntu18.04\",\n",
    "    # We don't need more than 1 instance. It's a small dataset.\n",
    "    instance_count=1,\n",
    "    # 32 vCPUs and 244 GiB of RAM\n",
    "    instance_type=\"ml.p2.8xlarge\",\n",
    "    # Point to our training script\n",
    "    entry_point=\"resnet50-cifar10.py\",\n",
    "    # Profiler and Debugger configuration\n",
    "    profiler_config=profiler_config,\n",
    "    debugger_hook_config=debugger_hook_config,\n",
    "    rules=rules\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensorflow-training-2022-02-18-21-15-00-600'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN!\n",
    "estimator.fit(wait=False)\n",
    "# Get the training job name\n",
    "estimator.latest_training_job.job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Now take a look at the Debugger Insights Dashboard to analyze debugging/profiling data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".... Go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. For a more thorough analysis, download the tensors collected by Debugger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job status:  InProgress\n",
      "Waiting for training job to start training...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a95ee4fd2233>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training job status: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Waiting for training job to start training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "def job_status():\n",
    "    description = client.describe_training_job(TrainingJobName=job_name)\n",
    "    return description[\"TrainingJobStatus\"]\n",
    "\n",
    "job_name = estimator.latest_training_job.name\n",
    "client = estimator.sagemaker_session.sagemaker_client\n",
    "\n",
    "\n",
    "while job_status() == \"InProgress\":\n",
    "    print(\"Training job status: \", job_status())\n",
    "    print(\"Waiting for training job to start training...\")\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensors are stored in:  s3://sagemaker-us-east-1-658994994074/tensorflow-training-2022-02-18-19-59-30-787/debug-output\n",
      "[2022-02-18 20:00:20.771 tensorflow-2-6-gpu--ml-g4dn-xlarge-0dac2104acc07d6f4758a14ad24a:284 INFO s3_trial.py:42] Loading trial debug-output at path s3://sagemaker-us-east-1-658994994074/tensorflow-training-2022-02-18-19-59-30-787/debug-output\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from urllib.parse import urlparse\n",
    "from smdebug.trials import create_trial\n",
    "\n",
    "# this is where we create a Trial object that allows access to saved tensors\n",
    "path = estimator.latest_job_debugger_artifacts_path()\n",
    "print(\"Tensors are stored in: \", path)\n",
    "trial = create_trial(estimator.latest_job_debugger_artifacts_path())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial1.steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.6 Python 3.8 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.6-gpu-py38-cu112-ubuntu20.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
